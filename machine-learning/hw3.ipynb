{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bryan Chen (bc2vf)<br>\n",
    "Comparative Algorithm Study<br><br>\n",
    "**Abstract**<br>\n",
    "This study compares the accuracy of the Decision Tree, k-Nearest Neighbor, Random Forest, AdaBoost and Support Vector Machine algorithms on detecting fraud in a dataset of credit card transactions from [Kaggle]( https://www.kaggle.com/dalpozz/creditcardfraud). I compared the five algorithms based on accuracy, precision, and recall and determined Random Forest to be best algorithm overall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "from matplotlib import gridspec\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./input/creditcard.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data**<br>\n",
    "The dataset is highly unbalanced. There are 492 frauds out of 284,807 transactions, so the positive class (frauds) account for only 0.172% of all transactions. There are no missing values, which is convenient. There is a large number of features, 31 overall, in which other than Time, Amount, and Class, they are anonymous (V)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold, SelectFromModel\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "counts = pd.value_counts(df['Class']).sort_index()\n",
    "counts.plot(kind='bar')\n",
    "pyplot.title('Fraud classes')\n",
    "pyplot.xlabel('Class (0 is non fraud)') \n",
    "pyplot.ylabel('Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The relationship of these V features is unknown, so I selected the features based on if the variance of the samples did not meet a threshold of 0.16. Since the classes are boolean values (0 or 1), I want to remove all features that are either one or zero (fraud or non fraud) in more of 80% of the samples. I removed features that have similar distributions between fraudulent and valid transactions in order to idnetify values where fraudulent transactions are more common. Boolean features are Bernoulli random variables, hence the variance is given by Var[x] = p(1-p) = 0.8*(1-0.8) = 0.16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isnull().sum()) # no null values\n",
    "X, y = df.values, df['Class'].values\n",
    "sel = VarianceThreshold(threshold=0.16)\n",
    "sel.fit_transform(X, y)\n",
    "X = sel.transform(X)  # two features were dropped from training due to low variances\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since I used the test set to both select the values of the parameter and evaluate the model, I risk optimistically biasing my model evaluations. For this reason, if a test set is used to select model parameters, then I need a different test set to get an unbiased evaluation of that selected model. I overcame this problem using nested cross validations. First, an inner cross validation is used to tune the parameters and select the best model. Second, an outer cross validation is used to evaluate the model selected by the inner cross validation. I also used scoring based on ROC AUC instead of accuracy.\n",
    "\n",
    "For KNN with 10-fold, with value of k=1, cv=0.99816, with k=3, cv=0.99842, with k=5, cv=0.998367, so 3 is the optimal k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_fold = KFold(n_splits=4, random_state=123)\n",
    "outer_fold = KFold(n_splits=5, random_state=123)\n",
    "dtc = DecisionTreeClassifier(max_features='sqrt')\n",
    "knn = KNeighborsClassifier(metric='euclidean')\n",
    "svc = SVC()\n",
    "rfc = RandomForestClassifier(oob_score=True, max_features='sqrt')\n",
    "adb = AdaBoostClassifier(base_estimator=dtc)\n",
    "models = [dtc, knn, svc, rfc, adb]\n",
    "titles = ['DT', 'KNN', 'SVM', 'RF', 'ADA']\n",
    "params = [\n",
    "    {'max_depth': [1, 5, 10, 20], 'criterion': ['gini', 'entropy']},\n",
    "    {'n_neighbors': [1, 3, 5, 7, 9, 11]},\n",
    "    {'C': [1, 10, 100], 'kernel': ['linear', 'rbf', 'poly', 'sigmoid'], 'gamma': ['0.01', '0.001', 'auto']},\n",
    "    {'n_estimators': [25, 50, 100], 'max_depth': [1, 5, 10, 20], 'min_samples_leaf': [1, 5, 10, 50, 100]},\n",
    "    {'n_estimators': [25, 50, 100], 'learning_rate': [0.05, 0.1, 0.2]}\n",
    "]\n",
    "cv_scores = pd.DataFrame(0, index=np.arange(len(models)), columns=titles)\n",
    "cm = [np.array([[0, 0], [0, 0]]) for _ in range(len(models))]\n",
    "iters = 0  # number of outer folds completed\n",
    "\n",
    "for train, test in outer_fold.split(X):\n",
    "    for i, clf in enumerate(models):\n",
    "        best_clf = GridSearchCV(\n",
    "            estimator=clf, \n",
    "            param_grid=params[i], \n",
    "            X=X[train], \n",
    "            y=y[train], \n",
    "            cv=inner_fold,\n",
    "            scoring='recall',  # best recall/precision because data unbalanced\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        best_clf.fit(X[train], y[train])\n",
    "        y_pred = best_clf.predict(X[test])\n",
    "        score = accuracy_score(y_true=y[test], y_pred=y_pred)\n",
    "        print(best_clf.best_params_ + '\\t' + best_clf.best_score_ + '\\t' + score)\n",
    "        cv_scores.iloc[iters, i] = score\n",
    "        np.add(cm[i], confusion_matrix(y_true=y[test], y_pred=y_pred, labels=['0', '1']))\n",
    "    iters += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mse = 1 - np.mean(cv_scores, axis=0)\n",
    "var = np.var(cv_scores, axis=0)\n",
    "\n",
    "# construct some data like what you have:\n",
    "\n",
    "# create stacked errorbars:\n",
    "# pyplot.figure()\n",
    "# pyplot.boxplot(cv_\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "for i, cnf_matrix in enumerate(cm):\n",
    "    plt.figure()\n",
    "    plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                          title=titles[i])\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
